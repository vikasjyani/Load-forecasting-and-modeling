"""
Pydantic models for data input, output, validation, and management.
"""
from pydantic import BaseModel, Field, HttpUrl
from typing import List, Dict, Any, Optional, Union
from datetime import datetime
from enum import Enum

class DataSourceType(str, Enum):
    """
    Enum for different types of data sources.
    """
    FILE_UPLOAD = "file_upload"
    DATABASE_TABLE = "database_table" # Placeholder, as DB is out of scope
    EXTERNAL_API = "external_api"
    INTERNAL_PROCESS = "internal_process" # e.g., generated by a model run
    USER_INPUT = "user_input"

class DataSourceBase(BaseModel):
    """
    Base model for a data source.
    """
    name: str = Field(..., min_length=3, max_length=100, example="Hourly Weather Data API")
    source_type: DataSourceType = Field(..., example=DataSourceType.EXTERNAL_API)
    description: Optional[str] = Field(None, max_length=500, example="Provides hourly weather observations and forecasts.")
    attributes: Dict[str, Any] = Field(default_factory=dict, example={"url": "https://api.weather.com/v1/hourly", "requires_key": True})

class DataSourceCreate(DataSourceBase):
    """
    Model for creating/registering a new data source.
    """
    pass # Inherits all from DataSourceBase, can add more fields if needed for creation

class DataSourceResponse(DataSourceBase):
    """
    Model for returning data source information.
    """
    datasource_id: str = Field(..., example="ds_weather_hourly_001")
    created_at: datetime = Field(default_factory=datetime.now)
    last_updated_at: datetime = Field(default_factory=datetime.now)
    is_active: bool = Field(default=True)

    class Config:
        orm_mode = True

class DataValidationRule(BaseModel):
    """
    Represents a single data validation rule that was applied or is applicable.
    """
    rule_name: str = Field(..., example="check_column_exists")
    column: Optional[str] = Field(None, example="Temperature")
    condition: Optional[str] = Field(None, example="not_null")
    expected_value: Optional[Any] = Field(None, example=None) # Or a regex, range, etc.
    description: Optional[str] = Field(None)

class DataIssue(BaseModel):
    """
    Represents a specific issue found during data validation.
    """
    issue_type: str = Field(..., example="MissingValue") # e.g., MissingValue, OutOfRange, InvalidFormat
    column: Optional[str] = Field(None, example="Pressure_hPa")
    row_identifier: Optional[Union[int, str]] = Field(None, example=102) # Row number or ID
    problematic_value: Optional[Any] = Field(None, example=None)
    message: str = Field(..., example="Pressure value is missing.")
    suggested_fix: Optional[str] = Field(None, example="Impute using mean or remove row.")

class DataValidationResult(BaseModel):
    """
    Represents the outcome of a validation check on a dataset or file.
    """
    file_name: Optional[str] = Field(None, example="input_data_q1_2024.csv")
    dataset_id: Optional[str] = Field(None, example="ds_temp_readings_raw")
    is_valid: bool = Field(..., example=False)
    validation_timestamp: datetime = Field(default_factory=datetime.now)
    checked_rules: Optional[List[DataValidationRule]] = Field(None)
    issues_found: List[DataIssue] = Field(default_factory=list)
    error_summary: Optional[Dict[str, int]] = Field(None, example={"MissingValue": 10, "InvalidFormat": 2}) # Count of issues by type
    warnings: Optional[List[str]] = Field(default_factory=list)

class DatasetMetadata(BaseModel):
    """
    Describes a dataset stored or managed by the system.
    """
    dataset_id: str = Field(..., example="annual_energy_consumption_cleaned")
    name: str = Field(..., example="Annual Energy Consumption (Cleaned)")
    description: Optional[str] = None
    source_ids: Optional[List[str]] = Field(None, example=["ds_utility_billing_001", "ds_manual_corrections_002"])
    data_format: Optional[str] = Field(None, example="CSV") # e.g., CSV, Parquet, JSON lines
    schema_definition: Optional[Dict[str, Any]] = Field(None, description="Column names and their types/constraints")
    temporal_coverage_start: Optional[datetime] = None
    temporal_coverage_end: Optional[datetime] = None
    spatial_coverage: Optional[str] = Field(None, example="National") # e.g., specific region, national
    tags: Optional[List[str]] = Field(default_factory=list, example=["energy", "consumption", "annual", "cleaned"])
    version: Optional[str] = Field(None, example="v1.2")
    created_at: datetime
    last_modified_at: datetime
    file_references: Optional[List['FileReference']] = None # Forward reference to FileReference in core.py

class DataFileDetails(BaseModel):
    """
    Provides details about a specific data file, often used in conjunction with project files.
    """
    project_name: str = Field(..., example="AlphaPVProject")
    file_path_relative: str = Field(..., description="Path relative to the project's data directory", example="inputs/historical_demand.xlsx")
    file_type: str = Field(..., example="Excel Workbook") # e.g., CSV, Excel Workbook, Parquet
    size_bytes: int = Field(..., example=204800)
    last_modified: datetime
    content_summary: Optional[Dict[str, Any]] = Field(None, description="e.g., sheet names for Excel, row/column count for CSV")
    is_input_file: Optional[bool] = Field(None, description="Is this considered a primary input file?")
    associated_outputs: Optional[List[str]] = Field(None, description="Relative paths to output files generated from this input")

# To handle the forward reference from DatasetMetadata to FileReference
from app.models.core import FileReference
DatasetMetadata.update_forward_refs()

class DataUploadRequest(BaseModel):
    """
    Model for requesting a data upload (e.g., to a specific project or dataset).
    Could be used with FastAPI's UploadFile. The actual file is handled separately.
    """
    project_name: Optional[str] = Field(None, example="ProjectPhoenix")
    dataset_name: Optional[str] = Field(None, example="RawSensorReadings_Q3")
    description: Optional[str] = Field(None, example="Raw sensor readings from plant A for Q3 2024.")
    tags: Optional[List[str]] = Field(None, example=["raw_data", "sensor", "plant_A"])
    # The file itself would be an UploadFile type in the endpoint
    # file: UploadFile = File(...)
    # file_content_type: Optional[str] = Field(None) # Will be derived from UploadFile

class DataCatalogEntry(BaseModel):
    """
    Represents an entry in a data catalog.
    """
    catalog_id: str = Field(..., example="cat_entry_001")
    name: str = Field(..., example="National Grid Demand Data")
    description: str
    data_type: str = Field(..., example="Time Series") # e.g., Time Series, Tabular, Geospatial
    source: str = Field(..., example="National Grid ESO API")
    update_frequency: Optional[str] = Field(None, example="Daily")
    access_url: Optional[HttpUrl] = Field(None) # If directly accessible
    metadata_link: Optional[HttpUrl] = Field(None) # Link to more detailed metadata
    tags: List[str] = Field(default_factory=list)
    is_available_locally: bool = Field(default=False)
    local_dataset_id: Optional[str] = Field(None) # If it corresponds to a DatasetMetadata
